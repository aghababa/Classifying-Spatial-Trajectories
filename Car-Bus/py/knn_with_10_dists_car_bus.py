# -*- coding: utf-8 -*-
"""KNN_with_10_dists_car_bus_September_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cvmwIt28aAyyTlNuJ_RvY1HvCWMUS_MP
"""

#pip install fastdtw
#pip install trjtrypy

pip install trjtrypy

import glob
import numpy as np 
import time
import math
import random
from scipy import linalg as LA
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import statsmodels.api as sm
from termcolor import colored

from google.colab import drive
drive.mount("/content/gdrive")

"""# install package"""

# Commented out IPython magic to ensure Python compatibility.
# to make a directory
# %cd 'gdrive/My Drive/traj-dist'

# to see in what directory we are in

pwd

# to install setup.py from the current directory
!python setup.py install

!pip install geohash2

"""# "######################" Now restart runtime "######################"

But don't run the above block
"""

import traj_dist.distance as tdist
import pickle

"""# Preprocessing data"""

def read_file(file_name):
    data = []
    with open(file_name, "r") as f:
        for line in f:
            item = line.strip().split(",")
            data.append(np.array(item))
    return np.array(data)

data1 = read_file('/content/gdrive/My Drive/Colab Notebooks/go_track_tracks.csv')[1:,:-1]
data2 = read_file('/content/gdrive/My Drive/Colab Notebooks/go_track_trackspoints.csv')[1:,1:4]

float1 = np.vectorize(float)
int1 = np.vectorize(int)
track_id = int1(data1[:,0])
labels = np.where(int1(data1[:,-1]) < 1.5, int1(data1[:,-1]), -1) 
traj = float1(data2)

trajec = [0] * 163

for i in range(163):
    trajec[i] = []
    I = np.where(traj[:,2] == track_id[i])
    trajec[i] = np.array([labels[i], traj[I]], dtype = 'object')

trajec = np.array(trajec)

trajectory = [0] * 163
trajectory_label_id = [0] * 163

for i in range(163):
    trajectory[i] = trajec[i][1][:,:2]
    trajectory_label_id[i] = np.array([trajec[i][1][:,:2], trajec[i][0], trajec[i][1][:,2][0]], dtype = 'object')
    
trajectory_label_id = np.array(trajectory_label_id, dtype = 'object')
trajectory = np.array(trajectory, dtype = 'object')


min_length = 10
max_length = 1000 #160 for balance data
l = 0
index = [] 
for i in range(163):
    if len(trajectory[i]) < min_length or len(trajectory[i]) > max_length:
        l = l + 1
    else:
        index.append(i)
        
print("l, 163-l=", l, 163-l)

trajectories = [0] * (163-l)
trajectories_label_id = [0] * (163-l)

j = 0
for i in range(163):
    if len(trajectory[i]) >= min_length and len(trajectory[i]) <= max_length:
        trajectories[j] = np.array(trajectory[i])
        trajectories_label_id[j] = trajectory_label_id[i]
        j = j + 1

trajectories_label_id = np.array(trajectories_label_id, dtype = 'object')
trajectories = np.array(trajectories, dtype = 'object')

cars = trajectories_label_id[np.where(trajectories_label_id[:,1] == 1)][:,:2][:,0]
buses = trajectories_label_id[np.where(trajectories_label_id[:,1] == -1)][:,:2][:,0]

def remove_segments(traj): # removes stationary points
    p2 = traj[1:]
    p1 = traj[:-1]
    L = ((p2-p1)*(p2-p1)).sum(axis =1)
    I = np.where(L>1e-16)[0]
    return traj[I]

cars = np.array(list(map(remove_segments, cars)), dtype='object')
buses = np.array(list(map(remove_segments, buses)), dtype='object')

cars_copy = cars.copy()
buses_copy = buses.copy()
print("len(cars), len(buses)=", len(cars), len(buses))

cars_11 = cars[11].copy()
cars_12 = cars[12].copy()

a = np.arange(len(cars))
I = np.where((a != 11) & (a != 12) & (a != 28) & (a != 29))
cars = cars[I]
buses = buses[:-1]
len(cars), len(buses)

cars = np.array([cars_11, cars_12] + list(cars), dtype='object')
cars.shape

a, c = np.min((np.min([np.min(cars[i], axis=0) for i in range(len(cars))], axis=0), 
       np.min([np.min(buses[i], axis=0) for i in range(len(buses))], axis=0)), axis=0)
  
b, d = np.max((np.max([np.max(cars[i], axis=0) for i in range(len(cars))], axis=0), 
               np.max([np.max(buses[i], axis=0) for i in range(len(buses))], axis=0)), axis=0)

m = 20
Q = np.ones((m,2))

Q[:,0] = (b - a + 0.001) * np.random.random_sample(m) + a - 0.02
Q[:,1] = (d - c + 0.001) * np.random.random_sample(m) + c - 0.01

def get_mu(data_1, data_2):
    a = np.mean([np.mean(data_1[i], 0) for i in range(len(data_1))], 0)
    b = np.mean([np.mean(data_2[i], 0) for i in range(len(data_2))], 0)
    c = abs(a-b)
    return max(c)

def error(A,B):
    return abs(A - B) / (abs(A) + abs(B))

"""# From github page: https://github.com/bguillouet/traj-dist

It includes 9 distances for trajectories including: Continuous Frechet, Discrete Frechet, Hausdorff, DTW, SSPD, LCSS, EDR, ERP.

## All but the continuous Frechet distance are really fast.

#### Calculate distances all together
"""

def calculate_dists(data1, data2, metrics, eps_lcss=0.02, eps_edr=0.02): 
    ''' eps_lcss: if metric = 'lcss', then eps_lcss is effective.
        eps_edr: if metric = 'edr', then eps_edr is effective.
        id: 1 if car-bus dataset is used and 2 if the generated data_1 and data_2 are used'''
    start_time = time.time() 
    data = np.concatenate((data1, data2), 0)
    n = len(data)
    for metric in metrics:
        if metric == 'lcss':
            A = tdist.pdist(data, metric, type_d="euclidean", eps=eps_lcss)
        elif metric == 'edr':
            A = tdist.pdist(data, metric, type_d="euclidean", eps=eps_edr)
        else: 
            A = tdist.pdist(data, metric)
        tri = np.zeros((n, n))
        tri[np.triu_indices(n, 1)] = A
        for i in range(1, n):
            for j in range(i):
                tri[i][j] = tri[j][i]
        np.savetxt('/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/'+metric+'-76-44.csv', 
                    tri, delimiter=',')

    total_time = time.time() - start_time
    return total_time

Metrics = ['discret_frechet', 'hausdorff', 'dtw', 'sspd', 'lcss', 'edr', 'erp']

calculate_dists(cars, buses, metrics=Metrics, eps_lcss=0.02, eps_edr=0.02)

#Metrics = ['frechet']

#calculate_dists(cars, buses, metrics=Metrics)

"""#### Calculate distances for continuous Frechet line by line by the following function. Then at the end concatenate them together."""

# data = np.concatenate((data1, data2), 0)
def calculate_dists_line_by_line_frechet(data, path, start_idx, end_idx): 
    n = len(data)
    for i in range(start_idx, end_idx):
        start_time = time.time()
        def f(traj):
            return tdist.frechet(data[i], traj)
        A = list(map(f, data[i+1:]))
        np.savetxt(path+str(i)+'.csv', A, delimiter=',') 
        total_time = time.time() - start_time
        print(f"time for step {i}: {total_time}")
    return total_time

path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/frechet lines/'
data = np.concatenate((cars, buses), 0) 
calculate_dists_line_by_line_frechet(data, path, start_idx=0, end_idx=len(data)-1)

"""### To stack the 1d generated vectors together to get the distance matrix of continuous Frechet distance we will use the following get_matrix function."""

def get_matrix(data1, data2, path):
    '''
    path is: 
    '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/frechet lines/'
    or
    '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus-generated)/frechet lines/'
    '''
    n = len(data1) + len(data2)
    matrix = np.zeros((n,n))
    for i in range(n-1):
        #matrix[i][i+1:] = np.array(pd.read_csv(path+str(i)+'.csv', header=None)).reshape(n-i-1,)
        matrix[i][i+1:] = np.loadtxt(path+str(i)+'.csv')
    for i in range(1, n):
        for j in range(i):
            matrix[i][j] = matrix[j][i]
    np.savetxt(path[:-14]+'frechet.csv', matrix, delimiter=',')
    return matrix

path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/frechet lines/'
A = get_matrix(cars, buses, path)
A.shape

"""# KNN with 8 distances: 

### Continuous Frechet, Discrete Frechet, Hausdorff, DTW, LCSS, SSPD, EDR, ERP
"""

def KNN_with_dists(n_1, n_2, dists_names, paths_to_dists):
    '''path example: '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/sspd.csv'
       dists_names: a list of distance names
       paths_to_dists: the paths list to the corresponding distancas (each path 
                       points out to the corresponding distance matrix)
       n_1: len(data_1)
       n_2: len(data_2)
       dist_name: the name of distance used to calculate sitance matrix 
       (the name is taken from a list above called metrics)'''

    train_errors = np.zeros(len(dists_names))
    test_errors = np.zeros(len(dists_names))

    I_1, J_1, y_train_1, y_test_1 = train_test_split(np.arange(n_1), 
                                                np.ones(n_1), test_size=0.3)
    I_2, J_2, y_train_2, y_test_2 = train_test_split(np.arange(n_1, n_1+n_2), 
                                                np.ones(n_2), test_size=0.3)
    labels = np.array([1]*n_1 + [0] * n_2)
    I = np.concatenate((I_1, I_2), 0)
    np.random.shuffle(I)
    J = np.concatenate((J_1, J_2), 0)
    np.random.shuffle(J)

    for i in range(len(dists_names)):

        dist_matrix = np.array(pd.read_csv(paths_to_dists[i],  header=None))

        D_train = dist_matrix[I][:, I]
        D_test = dist_matrix[J][:,I]
        train_labels = labels[I]
        test_labels = labels[J]

        clf = KNeighborsClassifier(n_neighbors=5, metric='precomputed')
        
        #Train the model using the training sets
        clf.fit(D_train, list(train_labels))

        #Predict labels for train dataset
        train_pred = clf.predict(D_train)
        train_errors[i] = sum(train_labels != train_pred)/len(I)
        
        #Predict labels for test dataset
        test_pred = clf.predict(D_test)
        test_errors[i] = sum((test_labels != test_pred))/len(J)
        
    return train_errors, test_errors

def KNN_average_error(data1, data2, num_trials, dists_names, paths_to_dists):

    '''dists_names: a list of distance names
       paths_to_dists: the paths list to the corresponding distancas (each path 
                       points out to the corresponding distance matrix)'''

    Start_time = time.time()

    train_errors = np.zeros((num_trials, len(dists_names)))
    test_errors = np.zeros((num_trials, len(dists_names)))

    for i in range(num_trials):
        tr_errors, ts_errors = KNN_with_dists(len(data1), len(data2), dists_names, paths_to_dists)
        train_errors[i] = tr_errors
        test_errors[i] = ts_errors

    train_error = np.mean(train_errors, axis=0)
    test_error = np.mean(test_errors, axis=0)
    std_test_error = np.std(test_errors, axis=0)

    Dict = {}
    for i in range(len(dists_names)):
        Dict[i+1] = [f"KNN with {dists_names[i]}", 
                     np.round(train_error[i], decimals = 4), 
                     np.round(test_error[i], decimals = 4), 
                     np.round(std_test_error[i], decimals = 4)]

    df = pd.DataFrame.from_dict(Dict, orient='index', columns=['Classifier',
                                'Train Error', 'Test Error', 'std'])
    print(colored(f"num_trials = {num_trials}", "blue"))
    print(colored(f'total time = {time.time() - Start_time}', 'green'))

    return (df, train_errors, test_errors, train_error, test_error)

Metrics = ['frechet', 'discret_frechet', 'hausdorff', 'dtw', 'lcss', 'sspd', 'edr', 'erp']

paths = []
eps = 0.02
for i in range(len(Metrics)):
    paths.append('/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/'+Metrics[i]+'-76-44.csv')

F = KNN_average_error(cars, buses, num_trials=50, dists_names=Metrics, paths_to_dists=paths)
F[0]

"""# KNN with fastdtw which is an approximate dtw"""

pip install fastdtw

from scipy.spatial.distance import euclidean
from fastdtw import fastdtw

dataa = np.concatenate((cars, buses), 0)
fastdtw_matrix = np.array([np.array([fastdtw(dataa[i], dataa[j])[0] for j in range(len(dataa))]) for i in range(len(dataa))])
fastdtw_matrix.shape

def KNN_with_fastdtw(n_1, n_2, dist_matrix):
    '''n_1: len(data_1)
       n_2: len(data_2)
       dist_name: the name of distance used to calculate sitance matrix 
       (the name is taken from a list above called metrics)'''

    I_1, J_1, y_train_1, y_test_1 = train_test_split(np.arange(n_1), 
                                                np.ones(n_1), test_size=0.3)
    I_2, J_2, y_train_2, y_test_2 = train_test_split(np.arange(n_1, n_1+n_2), 
                                                np.ones(n_2), test_size=0.3)
    labels = np.array([1]*n_1 + [0] * n_2)
    I = np.concatenate((I_1, I_2), 0)
    np.random.shuffle(I)
    J = np.concatenate((J_1, J_2), 0)
    np.random.shuffle(J)

    D_train = dist_matrix[I][:, I]
    D_test = dist_matrix[J][:,I]
    train_labels = labels[I]
    test_labels = labels[J]

    clf = KNeighborsClassifier(n_neighbors=5, metric='precomputed')
    
    #Train the model using the training sets
    clf.fit(D_train, list(train_labels))

    #Predict labels for train dataset
    train_pred = clf.predict(D_train)
    train_errors = sum(train_labels != train_pred)/len(I)
    
    #Predict labels for test dataset
    test_pred = clf.predict(D_test)
    test_errors = sum((test_labels != test_pred))/len(J)
        
    return train_errors, test_errors

def KNN_fastdtw_average_error(data1, data2, dist_matrix, num_trials):

    '''dists_names: a list of distance names
       paths_to_dists: the paths list to the corresponding distancas (each path 
                       points out to the corresponding distance matrix)'''

    Start_time = time.time()

    train_errors = np.zeros(num_trials)
    test_errors = np.zeros(num_trials)

    for i in range(num_trials):
        tr_errors, ts_errors = KNN_with_fastdtw(len(data1), len(data2), dist_matrix)
        train_errors[i] = tr_errors
        test_errors[i] = ts_errors

    train_error = np.mean(train_errors)
    test_error = np.mean(test_errors)
    std_test_error = np.std(test_errors)

    Dict = {}
    Dict[1] = [f"KNN with fastdtw", np.round(train_error, decimals = 4), 
               np.round(test_error, decimals = 4), 
               np.round(std_test_error, decimals = 4)]

    df = pd.DataFrame.from_dict(Dict, orient='index', columns=['Classifier',
                                'Train Error', 'Test Error', 'std'])
    print(colored(f"num_trials = {num_trials}", "blue"))
    print(colored(f'total time = {time.time() - Start_time}', 'green'))

    return (df, train_errors, test_errors, train_error, test_error)

E = KNN_fastdtw_average_error(cars, buses, dist_matrix=fastdtw_matrix, num_trials=50)
E[0]

"""# KNN with LSH"""

pip install trjtrypy

from google.colab import files
files.upload()

#import KNN_with_LSH_class
from KNN_with_LSH_class import KNN_with_LSH

KNN_with_LSH_class = KNN_with_LSH(cars, buses, number_circles=20, num_trials=50)
KNN_with_LSH_class.KNN_LSH_average_error()[0]

"""# KNN with soft-dtw is implemented in Anaconda as the package couldn't be installed on Google Colab."""

