{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Beijing-Frechet-and-LSH-August-28.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FjUDYLcS07zg",
        "2tCLYXpw0_8S",
        "OtvNA2bUW6yV",
        "9ixK1z3A1pbE",
        "HN38DUc11pbF",
        "fPl379Nj1pbG",
        "gzW44_aq1pbO",
        "-6y3HBZIwbd5",
        "oXa4_9Ck0sTi",
        "O-wPKtP8wf-F"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qut9wK0N7sL"
      },
      "source": [
        "pip install trjtrypy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXLgevM-1pa_"
      },
      "source": [
        "import glob\n",
        "import numpy as np \n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from scipy import linalg as LA\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHUirZ4Q2y8P",
        "outputId": "275af726-f448-4174-edc2-f0c7854c07b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjUDYLcS07zg"
      },
      "source": [
        "# install package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3lvO_zYcKQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec1b4b5-7ab7-470c-b0d7-63f12c21aaa4"
      },
      "source": [
        "# to make a directory\n",
        "%cd 'gdrive/My Drive/traj-dist'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/traj-dist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r64WIR-DUEY8"
      },
      "source": [
        "# to see in what directory we are in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uizep1yEchxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5a03a9-b6e8-4472-b9cf-b027d5aacbc4"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/traj-dist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFXlofdMaQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cffe2a7-74d2-4007-c89d-860644c2c4ed"
      },
      "source": [
        "# to install setup.py from the current directory\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:700: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/lib/python3.7/distutils/dist.py:274: UserWarning: Unknown distribution option: 'download_urt'\n",
            "  warnings.warn(msg)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing traj_dist.egg-info/PKG-INFO\n",
            "writing dependency_links to traj_dist.egg-info/dependency_links.txt\n",
            "writing requirements to traj_dist.egg-info/requires.txt\n",
            "writing top-level names to traj_dist.egg-info/top_level.txt\n",
            "adding license file 'LICENSE.txt'\n",
            "writing manifest file 'traj_dist.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "running build_ext\n",
            "skipping 'traj_dist/cydist/basic_geographical.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/basic_euclidean.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/sspd.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/dtw.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/lcss.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/hausdorff.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/discret_frechet.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/frechet.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/segment_distance.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/sowd.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/erp.c' Cython extension (up-to-date)\n",
            "skipping 'traj_dist/cydist/edr.c' Cython extension (up-to-date)\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/traj_dist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/example.py -> build/bdist.linux-x86_64/egg/traj_dist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/build_benchmark_data.py -> build/bdist.linux-x86_64/egg/traj_dist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/distance.py -> build/bdist.linux-x86_64/egg/traj_dist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/__init__.py -> build/bdist.linux-x86_64/egg/traj_dist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/benchmark.py -> build/bdist.linux-x86_64/egg/traj_dist\n",
            "creating build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/__init__.py -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/basic_geographical.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/basic_euclidean.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/sspd.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/dtw.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/lcss.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/hausdorff.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/discret_frechet.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/frechet.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/segment_distance.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/sowd.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/erp.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/cydist/edr.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/traj_dist/cydist\n",
            "creating build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/segment_distance.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/sowd.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/lcss.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/basic_euclidean.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/sspd.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/hausdorff.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/frechet.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/__init__.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/edr.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/discret_frechet.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/erp.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/basic_spherical.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/linecell.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "copying build/lib.linux-x86_64-3.7/traj_dist/pydist/dtw.py -> build/bdist.linux-x86_64/egg/traj_dist/pydist\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/example.py to example.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/build_benchmark_data.py to build_benchmark_data.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/distance.py to distance.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/benchmark.py to benchmark.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/segment_distance.py to segment_distance.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/sowd.py to sowd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/lcss.py to lcss.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/basic_euclidean.py to basic_euclidean.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/sspd.py to sspd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/hausdorff.py to hausdorff.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/frechet.py to frechet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/edr.py to edr.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/discret_frechet.py to discret_frechet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/erp.py to erp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/basic_spherical.py to basic_spherical.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/linecell.py to linecell.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/pydist/dtw.py to dtw.cpython-37.pyc\n",
            "creating stub loader for traj_dist/cydist/basic_geographical.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/basic_euclidean.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/sspd.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/dtw.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/lcss.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/hausdorff.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/discret_frechet.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/frechet.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/segment_distance.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/sowd.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/erp.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for traj_dist/cydist/edr.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/basic_geographical.py to basic_geographical.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/basic_euclidean.py to basic_euclidean.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/sspd.py to sspd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/dtw.py to dtw.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/lcss.py to lcss.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/hausdorff.py to hausdorff.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/discret_frechet.py to discret_frechet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/frechet.py to frechet.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/segment_distance.py to segment_distance.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/sowd.py to sowd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/erp.py to erp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_dist/cydist/edr.py to edr.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_dist.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_dist.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_dist.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_dist.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_dist.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "traj_dist.cydist.__pycache__.basic_euclidean.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.basic_geographical.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.discret_frechet.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.dtw.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.edr.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.erp.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.frechet.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.hausdorff.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.lcss.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.segment_distance.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.sowd.cpython-37: module references __file__\n",
            "traj_dist.cydist.__pycache__.sspd.cpython-37: module references __file__\n",
            "creating 'dist/traj_dist-1.1-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing traj_dist-1.1-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/traj_dist-1.1-py3.7-linux-x86_64.egg\n",
            "Extracting traj_dist-1.1-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding traj-dist 1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/traj_dist-1.1-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for traj-dist==1.1\n",
            "Searching for geohash2==1.1\n",
            "Reading https://pypi.org/simple/geohash2/\n",
            "Downloading https://files.pythonhosted.org/packages/3e/0d/c40ea785cc5fa33c2f1e796ee02e763207140542d7aae2c6ea413358c092/geohash2-1.1.tar.gz#sha256=0ed0583b1f4fc329f96d807c9a4cd895c7eed2c35479ac7b4a50725249997bda\n",
            "Best match: geohash2 1.1\n",
            "Processing geohash2-1.1.tar.gz\n",
            "Writing /tmp/easy_install-zqg4x_ql/geohash2-1.1/setup.cfg\n",
            "Running geohash2-1.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-zqg4x_ql/geohash2-1.1/egg-dist-tmp-vn6hk5m9\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving geohash2-1.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding geohash2 1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/geohash2-1.1-py3.7.egg\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pandas==1.1.5\n",
            "Best match: pandas 1.1.5\n",
            "Adding pandas 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Shapely==1.7.1\n",
            "Best match: Shapely 1.7.1\n",
            "Adding Shapely 1.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Cython==0.29.23\n",
            "Best match: Cython 0.29.23\n",
            "Adding Cython 0.29.23 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for docutils==0.17.1\n",
            "Best match: docutils 0.17.1\n",
            "Adding docutils 0.17.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for traj-dist==1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFyNWPPnc2UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0482e258-9112-4694-a2b9-7af4c2fb1d1c"
      },
      "source": [
        "!pip install geohash2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geohash2 in /usr/local/lib/python3.7/dist-packages/geohash2-1.1-py3.7.egg (1.1)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from geohash2) (0.17.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tCLYXpw0_8S"
      },
      "source": [
        "# \"######################\" Now restart runtime \"######################\"\n",
        "\n",
        "But don't run the above block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f4j8AQHt9-a"
      },
      "source": [
        "import traj_dist.distance as tdist\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtvNA2bUW6yV"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecwYvg601pbC",
        "outputId": "5a0ecca1-4409-4d85-9854-a18a7f766149"
      },
      "source": [
        "I = glob.glob('/content/gdrive/My Drive/Research/Beijing for 2ed paper/Chosen users for 4 pairs/**/*.plt',\n",
        "              recursive=True)\n",
        "S = list(set([I[i][:84] for i in range(len(I))]))\n",
        "user_idx = np.array([S[i][81:] for i in range(len(S))])\n",
        "print(user_idx)\n",
        "len(S), S[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['044' '040' '016' '015' '033' '125']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,\n",
              " '/content/gdrive/My Drive/Research/Beijing for 2ed paper/Chosen users for 4 pairs/044')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKI_0QmI1pbD"
      },
      "source": [
        "def read_file(path):\n",
        "    J = glob.glob(path, recursive=True)\n",
        "    data = [0] * len(J)\n",
        "    c = 0\n",
        "    for j in range(len(J)):\n",
        "        data[j] = []\n",
        "        with open(J[j], \"r\") as f:\n",
        "            for line in f:\n",
        "                if c > 6:\n",
        "                    item = line.strip().split(\",\")\n",
        "                    if len(item) == 7:\n",
        "                        data[j].append(np.array([float(item[0]), float(item[1]), \n",
        "                                                 float(item[4])]))\n",
        "                c += 1\n",
        "        data[j] = np.array(data[j])\n",
        "    return np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ixK1z3A1pbE"
      },
      "source": [
        "### data1[i] in the following is user_i from Beijing dataset \n",
        "\n",
        "trajectories have time dimension in data1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r6Ggr7G3hPA"
      },
      "source": [
        "users = np.array([15, 16, 33, 40, 44, 125])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YffTxq-T1pbE",
        "outputId": "b04f753c-c036-4ece-fee5-5be10a22136f"
      },
      "source": [
        "start_time = time.time()\n",
        "user_idx_int = np.array(list(map(int, user_idx)))\n",
        "data1 = []\n",
        "for i in [15, 16, 33, 40, 44, 125]:\n",
        "    idx = np.where(user_idx_int == i)[0][0]\n",
        "    path = S[idx]+'/**/*.plt'\n",
        "    J = glob.glob(path, recursive=True)\n",
        "    data1.append(read_file(path))\n",
        "data1 = np.array(data1)\n",
        "print(time.time() - start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "56.63820791244507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r96ZWpxQ5v_v",
        "outputId": "63c64d0b-5c24-4ae1-ae84-78cd2d6c19e8"
      },
      "source": [
        "[len(data1[i]) for i in range(len(data1))] # = [67, 51, 13, 27, 72, 57]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[67, 51, 13, 27, 72, 57]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MKHvbSb1pbE",
        "outputId": "c035fcbc-c478-443b-aa4b-27786f22770e"
      },
      "source": [
        "data_1 = data1 + 0\n",
        "len(data_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdXWa2gQ1pbF"
      },
      "source": [
        "def remove_segments(traj): # removes stationary points\n",
        "    p2 = traj[:,:2][1:]\n",
        "    p1 = traj[:,:2][:-1]\n",
        "    L = ((p2-p1)*(p2-p1)).sum(axis =1)\n",
        "    I = np.where(L>1e-16)[0]\n",
        "    return traj[I]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN38DUc11pbF"
      },
      "source": [
        "### In data_1 below:\n",
        "    (1) there is no stationary points\n",
        "    (2) there is no trajectories with more than 200 waypoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoYYYs9_1pbG",
        "outputId": "e04edd5a-0019-4a2b-bb9e-b1cf1ca82958"
      },
      "source": [
        "for i in range(len(data_1)):\n",
        "    data_1[i] = np.array(list(map(remove_segments, data_1[i])), dtype='object')\n",
        "    L = np.array([len(data_1[i][j]) for j in range(len(data_1[i]))])\n",
        "    I = np.where((L > 1000))[0]\n",
        "    data_1[i] = data_1[i][I]\n",
        "\n",
        "I = np.where(np.array([len(data_1[i]) for i in range(len(data_1))]) > 0)[0]\n",
        "data_1 = data_1[I]\n",
        "print(\"len(data_1) =\", len(data_1))\n",
        "print(\"selected users:\", users[I]) # now 0,1,2,3,4,5 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(data_1) = 6\n",
            "selected users: [ 15  16  33  40  44 125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPl379Nj1pbG"
      },
      "source": [
        "# Partitioning trajectories to less than 20 minutes long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5W6f28b1pbG"
      },
      "source": [
        "def partition(trajectory, threshold=20):\n",
        "    '''threshold is in minutes'''\n",
        "    trajectories = []\n",
        "    a = 24 * 60 * sum(trajectory[:,2][1:] - trajectory[:,2][:-1])\n",
        "    if a <= threshold:\n",
        "        return np.array(trajectory.reshape(1, len(trajectory), 3))\n",
        "    else: \n",
        "        i = 0\n",
        "        while a > threshold:\n",
        "            j = i + 0\n",
        "            val = 0\n",
        "            while val < threshold: \n",
        "                if i < len(trajectory) - 1:\n",
        "                    temp = val + 0\n",
        "                    val += 24 * 60 * (trajectory[:,2][1:][i] - trajectory[:,2][:-1][i])\n",
        "                    i += 1\n",
        "                else: \n",
        "                    break\n",
        "            if len(trajectory[j:i-1]) > 0:\n",
        "                trajectories.append(trajectory[j:i-1])\n",
        "            a = a - val\n",
        "        if len(trajectory[i:]) > 0:\n",
        "            trajectories.append(trajectory[i:])\n",
        "    return np.array(trajectories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSCG_eLC1pbH",
        "outputId": "66f7f65d-9927-4409-9185-d8d9e443c4bf"
      },
      "source": [
        "# 24 * 60 * (days_date('1899/12/30 2:50:06') - days_date('1899/12/30 2:20:06')) == 20 min\n",
        "Time = [0] * len(data_1)\n",
        "for i in range(len(data_1)):\n",
        "    Time[i] = []\n",
        "    for j in range(len(data_1[i])):\n",
        "        Time[i].append(24 * 60 * sum(data_1[i][j][:,2][1:] - data_1[i][j][:,2][:-1])) # = 20 minutes \n",
        "    Time[i] = np.array(Time[i], dtype='object')\n",
        "\n",
        "Time = np.array(Time, dtype='object')\n",
        "Time.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4WlBGXo1pbH",
        "outputId": "790a1ed1-cbc3-48f3-b4ec-52c881cf38bf"
      },
      "source": [
        "J = [np.where(Time[i] > 20)[0] for i in range(len(Time))]\n",
        "print(len(J))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebF1LUFo1pbI"
      },
      "source": [
        "### data3 below is the array of trajectories having less than 20 minutes long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVjTgzqi1pbI",
        "outputId": "fa5b10ae-a266-4561-d422-48bc2ff6f8ec"
      },
      "source": [
        "data3 = [0] * len(data_1)\n",
        "\n",
        "for i in range(len(data_1)):\n",
        "    data3[i] = []\n",
        "    for j in range(len(data_1[i])):\n",
        "        A = partition(data_1[i][j], threshold=20)\n",
        "        for k in range(len(A)):\n",
        "            data3[i].append(A[k])\n",
        "    data3[i] = np.array(data3[i], dtype='object')\n",
        "    \n",
        "data3 = np.array(data3, dtype='object')\n",
        "\n",
        "data3.shape, data3[0].shape, data3[0][0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6,), (302,), (150, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeY1Sopm1pbJ"
      },
      "source": [
        "data4 = data3 + 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV0rMX401pbJ"
      },
      "source": [
        "data4 is the users having between 100 and 200 trajectories and each has length between 10 and 200 trajectory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1Z9TOce1pbJ",
        "outputId": "4ecc2922-8c06-449c-c4b5-916a991888bd"
      },
      "source": [
        "for i in range(len(data4)):\n",
        "    A = np.array([len(data4[i][j]) for j in range(len(data4[i]))])\n",
        "    I = np.where((A > 10) & (A < 200))[0]\n",
        "    data4[i] = data4[i][I]\n",
        "    \n",
        "print(len(data4))\n",
        "A = np.array([len(data4[i]) for i in range(len(data4))])\n",
        "print(A)\n",
        "chosen_users = np.where((A > 100) & (A < 200))[0]\n",
        "data4 = data4[chosen_users]\n",
        "\n",
        "print(\"chosen users:\", chosen_users)\n",
        "print(\"len(data4) =\", len(data4))\n",
        "A = [len(data4[i]) for i in range(len(data4))]\n",
        "print(\"length of preprocessed users in data4:\", np.sort(A))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "[154 140 117 193 197 122]\n",
            "chosen users: [0 1 2 3 4 5]\n",
            "len(data4) = 6\n",
            "length of preprocessed users in data4: [117 122 140 154 193 197]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-9fP5u-1pbJ"
      },
      "source": [
        "### data2 is the same as data4 but without time dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waBRyauD1pbJ",
        "outputId": "22e2ce18-884c-4c15-fda4-35ee603dd7cb"
      },
      "source": [
        "data = data4 + 0\n",
        "for i in range(len(data)):\n",
        "    data[i] = np.array([data4[i][j][:,:2] for j in range(len(data4[i]))], dtype='object')\n",
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv6eq4jPViyl",
        "outputId": "4cc1b768-c43d-4514-9901-9ef5294c033d"
      },
      "source": [
        "[len(data[i]) for i in range(len(data))] # = [154, 140, 117, 193, 197, 122]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[154, 140, 117, 193, 197, 122]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0giNmXfVZ98"
      },
      "source": [
        "pairs =  [[0, 4], [0, 5], [1, 4], [2, 3]] # equivalent to [[4, 12], [4, 16], [5, 12], [8, 10]] in Anaconda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEwwrDFibBxl"
      },
      "source": [
        "def get_sigma(train_1, train_2):\n",
        "    a = np.mean([np.mean(train_1[i], 0) for i in range(len(train_1))], 0)\n",
        "    b = np.mean([np.mean(train_2[i], 0) for i in range(len(train_2))], 0)\n",
        "    return np.round(max(abs(a-b)), decimals=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFCPX6knbjvD",
        "outputId": "4643eda0-b262-44ac-bbc2-25ef8ea3081c"
      },
      "source": [
        "for i in range(4):\n",
        "    m, n = pairs[i]\n",
        "    print(get_sigma(data[m], data[n])) # r = 0.01,1,0.1,0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0086\n",
            "2.0693\n",
            "0.0424\n",
            "0.1256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfZ8HroCjA7l",
        "outputId": "511acf78-4094-4eb3-f366-f95a8a82b3a5"
      },
      "source": [
        "0.0086/0.01, 2.0693, 0.0424/0.1, 0.1256/0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.86, 2.0693, 0.424, 1.2559999999999998)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKffgZXzajJG"
      },
      "source": [
        "# waypoints max length calculator \n",
        "def length_max(x):\n",
        "    p1 = x[:-1]\n",
        "    p2 = x[1:]\n",
        "    L = np.sqrt(((p2-p1)*(p2-p1)).sum(axis =1))\n",
        "    return max(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtFsOKIvcFdF"
      },
      "source": [
        "def get_sigma_mean_max(data1, data2):\n",
        "    Mean_waypoints_1 = np.mean([length_max(data1[i]) for i in range(len(data1))])\n",
        "    Mean_waypoints_2 = np.mean([length_max(data2[i]) for i in range(len(data2))])\n",
        "    Mean1 = np.round(Mean_waypoints_1, decimals=3) \n",
        "    Mean2 = np.round(Mean_waypoints_2, decimals=3)\n",
        "    Mean = np.round((Mean_waypoints_1 + Mean_waypoints_2)/2, decimals=3)\n",
        "\n",
        "    Max_waypoints_1 = np.max([length_max(data1[i]) for i in range(len(data1))])\n",
        "    Max_waypoints_2 = np.max([length_max(data2[i]) for i in range(len(data2))])\n",
        "    Max1 = np.round(Max_waypoints_1, decimals=3) \n",
        "    Max2 = np.round(Max_waypoints_2, decimals=3)\n",
        "    Max = np.round((Max_waypoints_1 + Max_waypoints_2)/2, decimals=3)\n",
        "\n",
        "    return Mean1, Mean2, Max1, Max2, Mean, Max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ZLgUkxee1X",
        "outputId": "e0c7d86e-7dfd-491c-8595-9ab72acd9d98"
      },
      "source": [
        "for i in range(4):\n",
        "    m, n = pairs[i]\n",
        "    print(get_sigma_mean_max(data[m], data[n])[-2:]) # r = 0.01,1,0.1,0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.003, 0.051)\n",
            "(0.004, 0.114)\n",
            "(0.003, 0.05)\n",
            "(0.001, 0.018)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg6Uyp9AZ5qH"
      },
      "source": [
        "# From github page: https://github.com/bguillouet/traj-dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzW44_aq1pbO"
      },
      "source": [
        "## Generating distance matrices (Continuous Frechet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u68PSun4Worb",
        "outputId": "ac80650e-c55a-4466-9df8-6882e4dfc6cc"
      },
      "source": [
        "pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 4], [0, 5], [1, 4], [2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSr25bkXSOh"
      },
      "source": [
        "# data = np.concatenate((data1, data2), 0)\n",
        "def calculate_dists_line_by_line_frechet(data, pair_idx, start_idx, end_idx): \n",
        "    n = len(data)\n",
        "    for i in range(start_idx, end_idx):\n",
        "        start_time = time.time()\n",
        "        def f(traj):\n",
        "            return tdist.frechet(data[i], traj)\n",
        "        A = list(map(f, data[i+1:]))\n",
        "        np.savetxt('/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (Beijing)/frechet lines '+str(pair_idx)+'/'+str(i)+'.csv', \n",
        "                   A, delimiter=',')\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"time for step {i}: {total_time}\")\n",
        "    return total_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNmzqdPLYunC"
      },
      "source": [
        "#j = 0,1,2,3\n",
        "Data = np.concatenate((data[pairs[j][0]], data[pairs[j][1]]), 0)\n",
        "calculate_dists_line_by_line_frechet(Data, pair_idx=j, start_idx=0, end_idx=len(Data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6y3HBZIwbd5"
      },
      "source": [
        "## To stack the 1d generated vectors together to get the distance matrix of continuous Frechet distance we will use the following get_matrix function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6WoHcv6wRtR"
      },
      "source": [
        "def get_matrix(data1, data2, pair_idx, path):\n",
        "    '''\n",
        "    path is: \n",
        "    '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (Beijing)/frechet lines '\n",
        "    '''\n",
        "    n = len(data1) + len(data2)\n",
        "    matrix = np.zeros((n,n))\n",
        "    for i in range(n-1):\n",
        "        #matrix[i][i+1:] = np.array(pd.read_csv(path+str(i)+'.csv', header=None)).reshape(n-i-1,)\n",
        "        matrix[i][i+1:] = np.loadtxt(path+str(pair_idx)+'/'+str(i)+'.csv')\n",
        "    for i in range(1, n):\n",
        "        for j in range(i):\n",
        "            matrix[i][j] = matrix[j][i]\n",
        "    np.savetxt(path[:-14]+'frechet '+str(pair_idx)+'.csv', matrix, delimiter=',')\n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXa4_9Ck0sTi"
      },
      "source": [
        "# KNN with Continuous Frechet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOkPgAbQcUX5"
      },
      "source": [
        "def KNN_with_dists(n_1, n_2, dists_names, paths_to_dists):\n",
        "    '''path example: '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/sspd.csv'\n",
        "       dists_names: a list of distance names\n",
        "       paths_to_dists: the paths list to the corresponding distancas (each path \n",
        "                       points out to the corresponding distance matrix)\n",
        "       n_1: len(data_1)\n",
        "       n_2: len(data_2)\n",
        "       dist_name: the name of distance used to calculate sitance matrix \n",
        "       (the name is taken from a list above called metrics)'''\n",
        "\n",
        "    train_errors = np.zeros(len(dists_names))\n",
        "    test_errors = np.zeros(len(dists_names))\n",
        "\n",
        "    I_1, J_1, y_train_1, y_test_1 = train_test_split(np.arange(n_1), \n",
        "                                                np.ones(n_1), test_size=0.3)\n",
        "    I_2, J_2, y_train_2, y_test_2 = train_test_split(np.arange(n_1, n_1+n_2), \n",
        "                                                np.ones(n_2), test_size=0.3)\n",
        "    labels = np.array([1]*n_1 + [0] * n_2)\n",
        "    I = np.concatenate((I_1, I_2), 0)\n",
        "    np.random.shuffle(I)\n",
        "    J = np.concatenate((J_1, J_2), 0)\n",
        "    np.random.shuffle(J)\n",
        "\n",
        "    for i in range(len(dists_names)):\n",
        "\n",
        "        dist_matrix = np.array(pd.read_csv(paths_to_dists[i], header=None))\n",
        "\n",
        "        D_train = dist_matrix[I][:, I]\n",
        "        D_test = dist_matrix[J][:,I]\n",
        "        train_labels = labels[I]\n",
        "        test_labels = labels[J]\n",
        "\n",
        "        clf = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n",
        "        \n",
        "        #Train the model using the training sets\n",
        "        clf.fit(D_train, list(train_labels))\n",
        "\n",
        "        #Predict labels for train dataset\n",
        "        train_pred = clf.predict(D_train)\n",
        "        train_errors[i] = sum(train_labels != train_pred)/len(I)\n",
        "        \n",
        "        #Predict labels for test dataset\n",
        "        test_pred = clf.predict(D_test)\n",
        "        test_errors[i] = sum((test_labels != test_pred))/len(J)\n",
        "        \n",
        "    return train_errors, test_errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyyv66EdA_um"
      },
      "source": [
        "def KNN_average_error(data1, data2, num_trials, dists_names, paths_to_dists):\n",
        "\n",
        "    '''dists_names: a list of distance names\n",
        "       paths_to_dists: the paths list to the corresponding distancas (each path \n",
        "                       points out to the corresponding distance matrix)'''\n",
        "\n",
        "    Start_time = time.time()\n",
        "\n",
        "    train_errors = np.zeros((num_trials, len(dists_names)))\n",
        "    test_errors = np.zeros((num_trials, len(dists_names)))\n",
        "\n",
        "    for i in range(num_trials):\n",
        "        tr_errors, ts_errors = KNN_with_dists(len(data1), len(data2), dists_names, paths_to_dists)\n",
        "        train_errors[i] = tr_errors\n",
        "        test_errors[i] = ts_errors\n",
        "\n",
        "    train_error = np.mean(train_errors, axis=0)\n",
        "    test_error = np.mean(test_errors, axis=0)\n",
        "    std_test_error = np.std(test_errors, axis=0)\n",
        "\n",
        "    Dict = {}\n",
        "    for i in range(len(dists_names)):\n",
        "        Dict[i+1] = [f\"KNN with {dists_names[i]}\", \n",
        "                     np.round(train_error[i], decimals = 4), \n",
        "                     np.round(test_error[i], decimals = 4), \n",
        "                     np.round(std_test_error[i], decimals = 4)]\n",
        "\n",
        "    df = pd.DataFrame.from_dict(Dict, orient='index', columns=['Classifier',\n",
        "                                'Train Error', 'Test Error', 'std'])\n",
        "    print(colored(f\"num_trials = {num_trials}\", \"blue\"))\n",
        "    print(colored(f'total time = {time.time() - Start_time}', 'green'))\n",
        "\n",
        "    return (df, train_errors, test_errors, train_error, test_error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrYaNASePsdA"
      },
      "source": [
        "path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (Beijing)/frechet lines '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXONnnOlT6Ou"
      },
      "source": [
        "for j in range(len(pairs)):\n",
        "    A = get_matrix(data[pairs[j][0]], data[pairs[j][1]], pair_idx=j, path=path)\n",
        "    #print(A.shape, len(data[pairs[j][0]])+len(data[pairs[j][1]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLSeoQvTfVW",
        "outputId": "8dc6bc4e-753d-4984-f686-46ae9666a753"
      },
      "source": [
        "test_error = []\n",
        "test_std = []\n",
        "for j in range(len(pairs)):\n",
        "    F = KNN_average_error(data[pairs[j][0]], data[pairs[j][1]], num_trials=50, \n",
        "                        dists_names=['frechet'], \n",
        "                        paths_to_dists=[path[:-14]+'frechet '+str(j)+'.csv'])\n",
        "    print(colored(pairs[j], 'yellow'))\n",
        "    print('pair:', F[0])\n",
        "    print(colored('==========================================================', 'red'))\n",
        "    test_error.append(np.array(F[0])[0][2])\n",
        "    test_std.append(np.array(F[0])[0][3])\n",
        "print(colored(f'mean test error: {np.mean(test_error)}', 'magenta'))\n",
        "print(colored(f'mean std of error: {np.mean(test_std)}', 'blue'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 3.8871326446533203\u001b[0m\n",
            "\u001b[33m[0, 4]\u001b[0m\n",
            "pair:          Classifier  Train Error  Test Error     std\n",
            "1  KNN with frechet       0.2258      0.2714  0.0339\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 2.616995096206665\u001b[0m\n",
            "\u001b[33m[0, 5]\u001b[0m\n",
            "pair:          Classifier  Train Error  Test Error     std\n",
            "1  KNN with frechet       0.1397      0.1967  0.0432\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 3.426722764968872\u001b[0m\n",
            "\u001b[33m[1, 4]\u001b[0m\n",
            "pair:          Classifier  Train Error  Test Error     std\n",
            "1  KNN with frechet       0.1813      0.2547  0.0355\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 3.0371618270874023\u001b[0m\n",
            "\u001b[33m[2, 3]\u001b[0m\n",
            "pair:          Classifier  Train Error  Test Error     std\n",
            "1  KNN with frechet       0.1372       0.217  0.0364\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "\u001b[35mmean test error: 0.23494999999999996\u001b[0m\n",
            "\u001b[34mmean std of error: 0.037250000000000005\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-wPKtP8wf-F"
      },
      "source": [
        "# KNN with LSH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn2vLGsZOmwg",
        "outputId": "ff233b0d-835f-42c6-86d0-8ab5be1e86dc"
      },
      "source": [
        "pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 4], [0, 5], [1, 4], [2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_bXXhx_zbKH"
      },
      "source": [
        "#pip install trjtrypy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FbAUA16ijtA9",
        "outputId": "55aff4a6-3663-4213-b7df-bfa595b4c0ae"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "import KNN_with_LSH_class\n",
        "from KNN_with_LSH_class import KNN_with_LSH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1191929-76c2-4a57-87ea-2adcc8cd8e23\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1191929-76c2-4a57-87ea-2adcc8cd8e23\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving KNN_with_LSH_class.py to KNN_with_LSH_class.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtdH7QGXUNb0",
        "outputId": "37b5b9ee-7a13-4ef5-c46f-01de71557c80"
      },
      "source": [
        "test_error_LSH = []\n",
        "test_std_LSH = []\n",
        "for j in range(len(pairs)):\n",
        "    m, n = pairs[j]\n",
        "    print(len(data[m])+len(data[n]))\n",
        "    KNN_with_LSH_class = KNN_with_LSH(data[m], data[n], number_circles=20, num_trials=50)\n",
        "    F = KNN_with_LSH_class.KNN_LSH_average_error()\n",
        "    print(colored(pairs[j], 'yellow'))\n",
        "    print('pair:', F[0])\n",
        "    print(colored('==========================================================', 'red'))\n",
        "    test_error_LSH.append(np.array(F[0])[0][2])\n",
        "    test_std_LSH.append(np.array(F[0])[0][3])\n",
        "print(colored(f'mean test error: {np.mean(test_error_LSH)}', 'magenta'))\n",
        "print(colored(f'mean std of error: {np.mean(test_std_LSH)}', 'blue'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "351\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 12.805943965911865\u001b[0m\n",
            "\u001b[33m[0, 4]\u001b[0m\n",
            "pair:      Classifier  Train Error  Test Error     std\n",
            "1  KNN with LSH       0.3351      0.3806  0.0621\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "276\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 9.482008934020996\u001b[0m\n",
            "\u001b[33m[0, 5]\u001b[0m\n",
            "pair:      Classifier  Train Error  Test Error     std\n",
            "1  KNN with LSH       0.3977      0.3983  0.0827\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "337\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 12.003517150878906\u001b[0m\n",
            "\u001b[33m[1, 4]\u001b[0m\n",
            "pair:      Classifier  Train Error  Test Error     std\n",
            "1  KNN with LSH       0.3809      0.4124  0.0766\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "310\n",
            "\u001b[34mnum_trials = 50\u001b[0m\n",
            "\u001b[32mtotal time = 11.570326566696167\u001b[0m\n",
            "\u001b[33m[2, 3]\u001b[0m\n",
            "pair:      Classifier  Train Error  Test Error     std\n",
            "1  KNN with LSH       0.2817      0.2915  0.0974\n",
            "\u001b[31m==========================================================\u001b[0m\n",
            "\u001b[35mmean test error: 0.37070000000000003\u001b[0m\n",
            "\u001b[34mmean std of error: 0.0797\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA-C-zEHclzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}