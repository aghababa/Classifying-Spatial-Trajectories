# -*- coding: utf-8 -*-
"""KNN_with_10_dists_simulatad_car_bus_September_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yhT4Jbc-ysgKc4HlRfAg3U1u3NWRadOl
"""

#pip install fastdtw

pip install trjtrypy

import glob
import numpy as np 
import time
import math
import random
from scipy import linalg as LA
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import statsmodels.api as sm
from termcolor import colored

from google.colab import drive
drive.mount("/content/gdrive")

"""# install package"""

# Commented out IPython magic to ensure Python compatibility.
# to make a directory
# %cd 'gdrive/My Drive/traj-dist'

# to see in what directory we are in

pwd

# to install setup.py from the current directory
!python setup.py install

!pip install geohash2

"""# "######################" Now restart runtime "######################"

But don't run the above block
"""

import traj_dist.distance as tdist
import pickle

"""# Read the fixed datasets data_1 and data_2 from gdrive"""

data_1 = []
data_2 = []
for i in range(226):
    path = '/content/gdrive/My Drive/car-bus-generated/data_1/'+str(i)+'.csv'
    data_1.append(np.array(pd.read_csv(path, header=None)))

for i in range(220):
    path = '/content/gdrive/My Drive/car-bus-generated/data_2/'+str(i)+'.csv'
    data_2.append(np.array(pd.read_csv(path, header=None)))

data_1 = np.array(data_1, dtype = "object")
data_2 = np.array(data_2, dtype = "object")
print("data_1.shape, data_2.shape=", data_1.shape, data_2.shape)

def get_mu(data_1, data_2):
    a = np.mean([np.mean(data_1[i], 0) for i in range(len(data_1))], 0)
    b = np.mean([np.mean(data_2[i], 0) for i in range(len(data_2))], 0)
    c = abs(a-b)
    return max(c)

def error(A,B):
    return abs(A - B) / (abs(A) + abs(B))

"""# From github page: https://github.com/bguillouet/traj-dist

It includes 9 distances for trajectories including: Continuous Frechet, Discrete Frechet, Hausdorff, DTW, SSPD, LCSS, EDR, ERP.

## All but the continuous Frechet distance are really fast.

#### Calculate distances all together
"""

def calculate_dists(data1, data2, metrics, eps_lcss=0.02, eps_edr=0.02): 
    ''' eps_lcss: if metric = 'lcss', then eps_lcss is effective.
        eps_edr: if metric = 'edr', then eps_edr is effective.
        id: 1 if car-bus dataset is used and 2 if the generated data_1 and data_2 are used'''
    start_time = time.time() 
    data = np.concatenate((data1, data2), 0)
    n = len(data)
    for metric in metrics:
        if metric == 'lcss':
            A = tdist.pdist(data, metric, type_d="euclidean", eps=eps_lcss)
        elif metric == 'edr':
            A = tdist.pdist(data, metric, type_d="euclidean", eps=eps_edr)
        else: 
            A = tdist.pdist(data, metric)
        tri = np.zeros((n, n))
        tri[np.triu_indices(n, 1)] = A
        for i in range(1, n):
            for j in range(i):
                tri[i][j] = tri[j][i]
                
        np.savetxt('/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/'+metric+'.csv', 
                    tri, delimiter=',')

    total_time = time.time() - start_time
    return total_time

Metrics = ['discret_frechet', 'hausdorff', 'dtw', 'sspd', 'lcss', 'edr', 'erp']

calculate_dists(data_1, data_2, metrics=Metrics, eps_lcss=0.02, eps_edr=0.02)

#Metrics = ['frechet']

#calculate_dists(data_1, data_2, metrics=Metrics)

"""#### Calculate distances for continuous Frechet line by line by the following function. Then at the end concatenate them together."""

# data = np.concatenate((data1, data2), 0)
def calculate_dists_line_by_line_frechet(data, path, start_idx, end_idx): 
    n = len(data)
    for i in range(start_idx, end_idx):
        start_time = time.time()
        def f(traj):
            return tdist.frechet(data[i], traj)
        A = list(map(f, data[i+1:]))
        np.savetxt(path+str(i)+'.csv', A, delimiter=',') 
        total_time = time.time() - start_time
        print(f"time for step {i}: {total_time}")
    return total_time

path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/frechet lines/'
data = np.concatenate((data_1, data_2), 0) 
calculate_dists_line_by_line_frechet(data, path, start_idx=0, end_idx=len(data)-1)

# extra
Frechet_matrix = np.zeros((len(data), len(data)))
path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/frechet lines/'
for i in range(4):
    Frechet_matrix[i][i+1:] = np.loadtxt(path+str(i)+'.csv')

path_to_dists = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus-generated)/frechet.csv'
Frechet_matrix[4:][:, 4:] = np.array(pd.read_csv(path_to_dists, header=None))

for i in range(4):
    Frechet_matrix[:,i] = Frechet_matrix[i]

Frechet_matrix.shape

# extra
#path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/frechet.csv'
#np.savetxt(path, Frechet_matrix, delimiter=',')

# extra
A = np.array(pd.read_csv(path, header=None))
A.shape

"""### To stack the 1d generated vectors together to get the distance matrix of continuous Frechet distance we will use the following get_matrix function."""

def get_matrix(data1, data2, path):
    '''
    path is: 
    '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/frechet lines/'
    '''
    n = len(data1) + len(data2)
    matrix = np.zeros((n,n))
    for i in range(n-1):
        #matrix[i][i+1:] = np.array(pd.read_csv(path+str(i)+'.csv', header=None)).reshape(n-i-1,)
        matrix[i][i+1:] = np.loadtxt(path+str(i)+'.csv')
    for i in range(1, n):
        for j in range(i):
            matrix[i][j] = matrix[j][i]
    np.savetxt(path[:-14]+'frechet.csv', matrix, delimiter=',')
    return matrix

path = '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/frechet lines/'
A = get_matrix(data_1, data_2, path)
A.shape

"""# KNN with 8 distances: 

### Continuous Frechet, Discrete Frechet, Hausdorff, DTW, SSPD, LCSS, EDR, ERP
"""

def KNN_with_dists(n_1, n_2, dists_names, paths_to_dists):
    '''path example: '/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (car-bus)/sspd.csv'
       dists_names: a list of distance names
       paths_to_dists: the paths list to the corresponding distancas (each path 
                       points out to the corresponding distance matrix)
       n_1: len(data_1)
       n_2: len(data_2)
       dist_name: the name of distance used to calculate sitance matrix 
       (the name is taken from a list above called metrics)'''

    train_errors = np.zeros(len(dists_names))
    test_errors = np.zeros(len(dists_names))

    I_1, J_1, y_train_1, y_test_1 = train_test_split(np.arange(n_1), 
                                                np.ones(n_1), test_size=0.3)
    I_2, J_2, y_train_2, y_test_2 = train_test_split(np.arange(n_1, n_1+n_2), 
                                                np.ones(n_2), test_size=0.3)
    labels = np.array([1]*n_1 + [0] * n_2)
    I = np.concatenate((I_1, I_2), 0)
    np.random.shuffle(I)
    J = np.concatenate((J_1, J_2), 0)
    np.random.shuffle(J)

    for i in range(len(dists_names)):

        dist_matrix = np.array(pd.read_csv(paths_to_dists[i],  header=None))

        D_train = dist_matrix[I][:, I]
        D_test = dist_matrix[J][:,I]
        train_labels = labels[I]
        test_labels = labels[J]

        clf = KNeighborsClassifier(n_neighbors=5, metric='precomputed')
        
        #Train the model using the training sets
        clf.fit(D_train, list(train_labels))

        #Predict labels for train dataset
        train_pred = clf.predict(D_train)
        train_errors[i] = sum(train_labels != train_pred)/len(I)
        
        #Predict labels for test dataset
        test_pred = clf.predict(D_test)
        test_errors[i] = sum((test_labels != test_pred))/len(J)
        
    return train_errors, test_errors

def KNN_average_error(data1, data2, num_trials, dists_names, paths_to_dists):

    '''dists_names: a list of distance names
       paths_to_dists: the paths list to the corresponding distancas (each path 
                       points out to the corresponding distance matrix)'''

    Start_time = time.time()

    train_errors = np.zeros((num_trials, len(dists_names)))
    test_errors = np.zeros((num_trials, len(dists_names)))

    for i in range(num_trials):
        tr_errors, ts_errors = KNN_with_dists(len(data1), len(data2), dists_names, paths_to_dists)
        train_errors[i] = tr_errors
        test_errors[i] = ts_errors

    train_error = np.mean(train_errors, axis=0)
    test_error = np.mean(test_errors, axis=0)
    std_test_error = np.std(test_errors, axis=0)

    Dict = {}
    for i in range(len(dists_names)):
        Dict[i+1] = [f"KNN with {dists_names[i]}", 
                     np.round(train_error[i], decimals = 4), 
                     np.round(test_error[i], decimals = 4), 
                     np.round(std_test_error[i], decimals = 4)]

    df = pd.DataFrame.from_dict(Dict, orient='index', columns=['Classifier',
                                'Train Error', 'Test Error', 'std'])
    print(colored(f"num_trials = {num_trials}", "blue"))
    print(colored(f'total time = {time.time() - Start_time}', 'green'))

    return (df, train_errors, test_errors, train_error, test_error)

Metrics = ['frechet', 'discret_frechet', 'hausdorff', 'dtw', 'lcss', 'sspd', 'edr', 'erp']

paths = []
eps = 0.02
for i in range(len(Metrics)):
    paths.append('/content/gdrive/My Drive/traj-dist/Calculated Distance Matrices (simulated-car-bus)/'+Metrics[i]+'.csv')

F = KNN_average_error(data_1, data_2, num_trials=50, dists_names=Metrics, paths_to_dists=paths)
F[0]

"""# KNN with fastdtw which is an approximate dtw"""

pip install fastdtw

from scipy.spatial.distance import euclidean
from fastdtw import fastdtw

data_1_2 = np.concatenate((data_1, data_2), 0)
fastdtw_matrix_1_2 = np.array([np.array([fastdtw(data_1_2[i], data_1_2[j])[0] for j in range(len(data_1_2))]) for i in range(len(data_1_2))])
fastdtw_matrix_1_2.shape

def KNN_with_fastdtw(n_1, n_2, dist_matrix):
    '''n_1: len(data_1)
       n_2: len(data_2)
       dist_name: the name of distance used to calculate sitance matrix 
       (the name is taken from a list above called metrics)'''

    I_1, J_1, y_train_1, y_test_1 = train_test_split(np.arange(n_1), 
                                                np.ones(n_1), test_size=0.3)
    I_2, J_2, y_train_2, y_test_2 = train_test_split(np.arange(n_1, n_1+n_2), 
                                                np.ones(n_2), test_size=0.3)
    labels = np.array([1]*n_1 + [0] * n_2)
    I = np.concatenate((I_1, I_2), 0)
    np.random.shuffle(I)
    J = np.concatenate((J_1, J_2), 0)
    np.random.shuffle(J)

    D_train = dist_matrix[I][:, I]
    D_test = dist_matrix[J][:,I]
    train_labels = labels[I]
    test_labels = labels[J]

    clf = KNeighborsClassifier(n_neighbors=5, metric='precomputed')
    
    #Train the model using the training sets
    clf.fit(D_train, list(train_labels))

    #Predict labels for train dataset
    train_pred = clf.predict(D_train)
    train_errors = sum(train_labels != train_pred)/len(I)
    
    #Predict labels for test dataset
    test_pred = clf.predict(D_test)
    test_errors = sum((test_labels != test_pred))/len(J)
        
    return train_errors, test_errors

def KNN_fastdtw_average_error(data1, data2, dist_matrix, num_trials):

    '''dists_names: a list of distance names
       paths_to_dists: the paths list to the corresponding distancas (each path 
                       points out to the corresponding distance matrix)'''

    Start_time = time.time()

    train_errors = np.zeros(num_trials)
    test_errors = np.zeros(num_trials)

    for i in range(num_trials):
        tr_errors, ts_errors = KNN_with_fastdtw(len(data1), len(data2), dist_matrix)
        train_errors[i] = tr_errors
        test_errors[i] = ts_errors

    train_error = np.mean(train_errors)
    test_error = np.mean(test_errors)
    std_test_error = np.std(test_errors)

    Dict = {}
    Dict[1] = [f"KNN with fastdtw", np.round(train_error, decimals = 4), 
               np.round(test_error, decimals = 4), 
               np.round(std_test_error, decimals = 4)]

    df = pd.DataFrame.from_dict(Dict, orient='index', columns=['Classifier',
                                'Train Error', 'Test Error', 'std'])
    print(colored(f"num_trials = {num_trials}", "blue"))
    print(colored(f'total time = {time.time() - Start_time}', 'green'))

    return (df, train_errors, test_errors, train_error, test_error)

E = KNN_fastdtw_average_error(data_1, data_2, dist_matrix=fastdtw_matrix_1_2, num_trials=50)
E[0]

"""# KNN with LSH"""

pip install trjtrypy

from google.colab import files
files.upload()

#import KNN_with_LSH_class
from KNN_with_LSH_class import KNN_with_LSH

KNN_with_LSH_class = KNN_with_LSH(data_1, data_2, number_circles=20, num_trials=50)
KNN_with_LSH_class.KNN_LSH_average_error()[0]

"""# KNN with soft-dtw is implemented in Anaconda as the package couldn't be installed on Google Colab."""

